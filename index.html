<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Face Detection</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        video {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 0;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1;
        }

           .navbar {
               display:block;
      display: flex;
      justify-content: center;
      background-color: #333;
      padding: 10px;
                   z-index: 1000; /* Ensures the navbar is on top of other content */
    }
    .navbar a {
      color: white;
      text-decoration: none;
      padding: 14px 20px;
      text-align: center;
      font-size: 16px;
    }
    .navbar a:hover {
      background-color: #575757;
    }
    </style>
</head>
<body>
     <div class="navbar">
    <a href="index.html">Face-detection</a>
    <a href="index-2.html">FaceLanmarker</a>
  </div>
    <video id="video" autoplay></video>
    <canvas id="canvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let model;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true
            });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve();
                };
            });
        }

        async function setupModel() {
            model = await blazeface.load();
        }

        async function detectFaces() {
            if (!model) {
                console.error('Model not loaded');
                return;
            }

            const predictions = await model.estimateFaces(video, false);

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            predictions.forEach(prediction => {
                const [x, y, width, height] = prediction.topLeft.concat(prediction.bottomRight).map(coord => Math.round(coord));
                ctx.beginPath();
                ctx.rect(x, y, width - x, height - y);
                ctx.lineWidth = 2;
                ctx.strokeStyle = 'red';
                ctx.stroke();
            });

            requestAnimationFrame(detectFaces);
        }

        async function main() {
            await setupCamera();
            video.play();
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            await setupModel();
            detectFaces();
        }

        main();
    </script>
</body>
</html>
